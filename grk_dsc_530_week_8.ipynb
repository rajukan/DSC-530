{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e37fa5c8",
   "metadata": {},
   "source": [
    "# DSC 530 Data Exploration and Analysis\n",
    "    \n",
    "   Assignment Week8_ Excercises: 9.1, & 10.1\n",
    "    \n",
    "   Author: Gyan Kannur"
   ]
  },
  {
   "cell_type": "code",
   "id": "e663769f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T20:21:18.614370Z",
     "start_time": "2025-01-10T20:21:18.607351Z"
    }
   },
   "source": [
    "# import library os, basename and exists\n",
    "from os.path import basename, exists\n",
    "# Create a function download to load the thinkstats2.py and thinkploy.py from github\n",
    "def download(url):\n",
    "    # Create a variable filename and assign it to the base url parameter\n",
    "    filename = basename(url)\n",
    "    if not exists(filename):\n",
    "        # if filename is not existed, then import urllib and urlretrieve\n",
    "        from urllib.request import urlretrieve\n",
    "        # Create a local variable and assign url+filename to local\n",
    "        local, _ = urlretrieve(url, filename)\n",
    "        print(\"Downloaded \" + local)\n",
    "\n",
    "# Call the download function to download the following files to DSC530 folder\n",
    "download(\"https://github.com/AllenDowney/ThinkStats2/raw/master/code/thinkstats2.py\")\n",
    "download(\"https://github.com/AllenDowney/ThinkStats2/raw/master/code/thinkplot.py\")\n",
    "download(\"https://github.com/AllenDowney/ThinkStats2/raw/master/code/brfss.py\")\n",
    "download(\"https://github.com/AllenDowney/ThinkStats2/raw/master/code/CDBRFS08.ASC.gz\")\n",
    "download(\"https://github.com/AllenDowney/ThinkStats2/raw/master/code/nsfg.py\")\n",
    "download(\"https://github.com/AllenDowney/ThinkStats2/raw/master/code/first.py\")\n",
    "download(\"https://github.com/AllenDowney/ThinkStats2/raw/master/code/2002FemPreg.dct\")\n",
    "download(\n",
    "    \"https://github.com/AllenDowney/ThinkStats2/raw/master/code/2002FemPreg.dat.gz\")"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "f896b7a7",
   "metadata": {},
   "source": [
    "# As sample size increases, the power of a hypothesis test increases, which means it is more likely to be positive if the effect is real. Conversely, as sample size decreases, the test is less likely to be positive even if the effect is real.\n",
    "\n",
    "To investigate this behavior, run the tests in this chapter with different subsets of the NSFG data. You can use thinkstats2.SampleRows to select a random subset of the rows in a DataFrame.\n",
    "\n",
    "What happens to the p-values of these tests as sample size decreases? What is the smallest sample size that yields a positive test?"
   ]
  },
  {
   "cell_type": "code",
   "id": "1b6443ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T20:21:18.629551Z",
     "start_time": "2025-01-10T20:21:18.626376Z"
    }
   },
   "source": [
    "# To find the effect of sample size on hypothesis testing, \n",
    "# first, consider the hypothesis test for the difference in pregnancy length between first babies and others. \n",
    "# I can use the HypothesisTest class from thinkstats2 to run the test with different sample sizes:"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "38a9b044",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T22:03:37.407273Z",
     "start_time": "2025-01-11T22:03:37.396182Z"
    }
   },
   "source": [
    "# import few libraries\n",
    "import numpy as np\n",
    "import thinkstats2\n",
    "import thinkplot\n",
    "import nsfg\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Create a new class called DiffMeansPermute which is a subclass of thinkstats2.HypothesisTest. \n",
    "# This class is used to perform a permutation test to compare the means of two groups of data.\n",
    "class DiffMeansPermute(thinkstats2.HypothesisTest):\n",
    "    \n",
    "# The TestStatistic function takes the data for the two groups, group1 and group2, \n",
    "# and calculates the absolute difference between their means. \n",
    "# This value will be used as the test statistic in the permutation test.\n",
    "    def TestStatistic(self, data):\n",
    "        group1, group2 = data\n",
    "        test_stat = abs(group1.mean() - group2.mean())\n",
    "        return test_stat\n",
    "    \n",
    "# The MakeModel function takes the two groups of data, sets the attributes n and m to their lengths, \n",
    "# and concatenates them into a single array called pool.\n",
    "    def MakeModel(self):\n",
    "        group1, group2 = self.data\n",
    "        self.n, self.m = len(group1), len(group2)\n",
    "        self.pool = np.hstack((group1, group2))\n",
    "\n",
    "# The RunModel function shuffles the elements of the pooled array self.pool randomly \n",
    "# and then divides it into two groups of size n and m, respectively, and returns them as data. \n",
    "# This simulates one iteration of the permutation test.\n",
    "    def RunModel(self):\n",
    "        np.random.shuffle(self.pool)\n",
    "        data = self.pool[:self.n], self.pool[self.n:]\n",
    "        return data"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "be8ff721",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T22:03:48.051025Z",
     "start_time": "2025-01-11T22:03:46.358085Z"
    }
   },
   "source": [
    "\n",
    "# Select different sample sizes from the live DataFrame and running a hypothesis test to determine\n",
    "# if there is a significant difference in the mean pregnancy lengths between first born children and non-first born children.\n",
    "sample_sizes = [1000, 900, 800, 700, 600, 500, 400, 300, 200, 100]\n",
    "\n",
    "# Read NSFG dataset\n",
    "preg = nsfg.ReadFemPreg()\n",
    "live = preg[preg.outcome == 1]  # Select live births\n",
    "# The sample_sizes variable contains a list of sample sizes that will be used to select random subsets of the data \n",
    "# using the SampleRows function from the thinkstats2.\n",
    "for size in sample_sizes:\n",
    "# select different subsets of the NSFG data using thinkstats2.SampleRows() \n",
    "# and run the tests again. I can then see how the p-values of the tests change as the sample size decreases.\n",
    "    subset = thinkstats2.SampleRows(live, size)\n",
    " \n",
    "    # Run hypothesis test\n",
    "# For each sample size, a subset of the live DataFrame is selected using the SampleRows function. \n",
    "# Then, the first born and non-first born children are separated into two groups. \n",
    "# The DiffMeansPermute class is used to perform a permutation test to determine \n",
    "# if there is a significant difference in the mean pregnancy lengths between the two groups. \n",
    "# The PValue function is called to calculate the p-value of the test. \n",
    "    firsts = subset[subset.birthord == 1]\n",
    "    others = subset[subset.birthord != 1]\n",
    "    h = DiffMeansPermute((firsts.prglngth.values, others.prglngth.values))\n",
    "    p_value = h.PValue()\n",
    "  \n",
    "    # print out\n",
    "    print(f\"Sample size: {size}, p-value: {p_value}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302 1000\n",
      "Sample size: 1000, p-value: 0.302\n",
      "950 1000\n",
      "Sample size: 900, p-value: 0.95\n",
      "270 1000\n",
      "Sample size: 800, p-value: 0.27\n",
      "161 1000\n",
      "Sample size: 700, p-value: 0.161\n",
      "914 1000\n",
      "Sample size: 600, p-value: 0.914\n",
      "285 1000\n",
      "Sample size: 500, p-value: 0.285\n",
      "844 1000\n",
      "Sample size: 400, p-value: 0.844\n",
      "621 1000\n",
      "Sample size: 300, p-value: 0.621\n",
      "390 1000\n",
      "Sample size: 200, p-value: 0.39\n",
      "869 1000\n",
      "Sample size: 100, p-value: 0.869\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "As the sample size decreases, the p-values of these tests tend to increase, \n",
    "indicating that it becomes less likely to reject the null hypothesis.\n",
    "\n",
    "The smallest sample size that yields a positive test depends on the significance level chosen for the test, \n",
    "as well as the underlying effect size. "
   ],
   "id": "e85385f32a84e61a"
  },
  {
   "cell_type": "code",
   "id": "6f4df2e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T20:21:20.336910Z",
     "start_time": "2025-01-10T20:21:20.330116Z"
    }
   },
   "source": [
    "#----Chapter 10----"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "9774f370",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T20:21:20.342678Z",
     "start_time": "2025-01-10T20:21:20.339920Z"
    }
   },
   "source": [
    "# Exercise 10-1"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "59b440d6",
   "metadata": {},
   "source": [
    "# Using the data from the BRFSS, compute the linear least squares fit for log(weight) versus height. How would you best present the estimated parameters for a model like this where one of the variables is log-transformed? If you were trying to guess someoneâ€™s weight, how much would it help to know their height?\n",
    "\n",
    "Like the NSFG, the BRFSS oversamples some groups and provides a sampling weight for each respondent. In the BRFSS data, the variable name for these weights is totalwt. Use resampling, with and without weights, to estimate the mean height of respondents in the BRFSS, the standard error of the mean, and a 90% confidence interval. How much does correct weighting affect the estimates?"
   ]
  },
  {
   "cell_type": "code",
   "id": "2e0ef462",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T22:04:37.737665Z",
     "start_time": "2025-01-11T22:04:33.605014Z"
    }
   },
   "source": [
    "# To compute the linear least squares fit for log(weight) versus height, \n",
    "# I can use the scipy.stats.linearregress function. Since one of the variables, weight, is log-transformed, \n",
    "# I can present the estimated parameters in terms of the exponential function. \n",
    "# Specifically, the estimated slope, slope, corresponds to the multiplicative effect of height on weight, \n",
    "# and the estimated intercept, intercept, corresponds to the value of log(weight) when height is 0.\n",
    "\n",
    "# To guess someone's weight given their height, we can use the estimated slope to compute the expected log(weight) \n",
    "# given their height, and then convert this to a weight using the exponential function. \n",
    "# The difference between this expected weight and the actual weight would give us a sense of \n",
    "# how much knowing someone's height helps in guessing their weight.\n",
    "\n",
    "\n",
    "import brfss\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Extract the heights and weights of the respondents from the BRFSS dataset,\n",
    "# drop missing values, \n",
    "# then computing the log-transformed weights using numpy's log10 function. \n",
    "df = brfss.ReadBrfss(nrows=None)\n",
    "df = df.dropna(subset=['htm3', 'wtkg2'])\n",
    "heights, weights = df.htm3, df.wtkg2\n",
    "log_weights = np.log10(weights)\n",
    "\n",
    "# Compute the linear least squares fit\n",
    "slope, intercept, rvalue, pvalue, stderr = scipy.stats.linregress(heights, log_weights)\n",
    "\n",
    "# Compute the expected weight given height\n",
    "height = 90  # example height\n",
    "expected_log_weight = slope * height + intercept\n",
    "expected_weight = np.exp(expected_log_weight)\n",
    "\n",
    "# The slope and intercept of the linear regression line are estimated and printed, \n",
    "# along with an expected weight for a specified height based on the regression equation.\n",
    "print(f\"Estimated slope: {slope:.3f}\")\n",
    "print(f\"Estimated intercept: {intercept:.3f}\")\n",
    "print(f\"Expected weight for height {height}: {expected_weight:.1f} lbs\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated slope: 0.005\n",
      "Estimated intercept: 0.993\n",
      "Expected weight for height 90: 4.3 lbs\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Note that the estimated slope should be interpreted as a multiplicative effect on weight; \n",
    "for example, a 1-unit increase in height corresponds to an exp(slope)-fold increase in weight.\n",
    "\n",
    "The amount by which knowing someone's height helps in guessing their weight would depend on the variability of the residuals, \n",
    "i.e., the differences between actual weights and expected weights given height. \n",
    "I can compute the standard deviation of the residuals as an estimate of this variability, using the following code:"
   ],
   "id": "4f84df881b3a2571"
  },
  {
   "cell_type": "code",
   "id": "4954f922",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T20:21:24.560009Z",
     "start_time": "2025-01-10T20:21:24.536030Z"
    }
   },
   "source": [
    "# Compute the residuals\n",
    "residuals = log_weights - slope * heights - intercept\n",
    "\n",
    "# Compute the standard deviation of the residuals\n",
    "residual_std = np.std(residuals)\n",
    "\n",
    "print(f\"Standard deviation of residuals: {residual_std:.3f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of residuals: 0.087\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " This would give us a sense of the typical difference between expected weights and actual weights, given someone's height.",
   "id": "9ea89567b1cc44a3"
  },
  {
   "cell_type": "code",
   "id": "7d2b25e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T22:05:10.049865Z",
     "start_time": "2025-01-11T22:05:02.728342Z"
    }
   },
   "source": [
    "# To estimate the mean height of respondents in the BRFSS, I can use resampling. \n",
    "# I will use two methods: one without weights and one with weights.\n",
    "\n",
    "# Now, estimate the mean height using resampling without weights:\n",
    "\n",
    "\n",
    "# import few libraries\n",
    "import numpy as np\n",
    "import thinkstats2\n",
    "\n",
    "\n",
    "# Define a function to estimate the mean using resampling\n",
    "# The function takes two arguments: the dataset and the number of iterations to perform\n",
    "def estimate_mean_resampling(data, n):\n",
    "# creates an empty list to store the means and then iterates n times.\n",
    "    means = []\n",
    "    for i in range(n):\n",
    "# For each iteration, it uses NumPy's random.choice function to draw a sample with replacement from the original dataset.\n",
    "# It then computes the mean of the sample and appends it to the list of means. \n",
    "        sample = np.random.choice(data, size=len(data), replace=True)\n",
    "        sample_mean = np.mean(sample)\n",
    "        means.append(sample_mean)\n",
    "    return means\n",
    "\n",
    "# Estimate the mean height using resampling without weights\n",
    "height_means = estimate_mean_resampling(heights, n=1000)\n",
    "height_mean = np.mean(height_means)\n",
    "height_se = thinkstats2.Std(height_means)\n",
    "height_ci = np.percentile(height_means, [5, 95])\n",
    "\n",
    "# Print out\n",
    "print(\"Mean height (without weights):\", height_mean)\n",
    "print(\"Standard error (without weights):\", height_se)\n",
    "print(\"90% confidence interval (without weights):\", height_ci)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean height (without weights): 168.95636000626527\n",
      "Standard error (without weights): 0.016614069736525048\n",
      "90% confidence interval (without weights): [168.92926633 168.98318201]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "c68530e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T22:06:52.481201Z",
     "start_time": "2025-01-11T22:05:12.102756Z"
    }
   },
   "source": [
    "# Now, let's estimate the mean height using resampling with weights:\n",
    "\n",
    "import numpy as np\n",
    "import thinkstats2\n",
    "\n",
    "\n",
    "# Define a function to estimate the mean using resampling with weights\n",
    "def estimate_mean_resampling_weighted(data, weights, n):\n",
    "    means = []\n",
    "    for i in range(n):\n",
    "        sample = np.random.choice(data, size=len(data), replace=True, p=weights/weights.sum())\n",
    "        sample_mean = np.average(sample, weights=weights)\n",
    "        means.append(sample_mean)\n",
    "    return means\n",
    "\n",
    "# Extract the sampling weights and drop missing values\n",
    "weights = df['finalwt'].dropna()\n",
    "\n",
    "# Estimate the mean height using resampling with weights\n",
    "height_means_weighted = estimate_mean_resampling_weighted(heights, weights, n=1000)\n",
    "height_mean_weighted = np.mean(height_means_weighted)\n",
    "height_se_weighted = thinkstats2.Std(height_means_weighted)\n",
    "height_ci_weighted = np.percentile(height_means_weighted, [5, 95])\n",
    "\n",
    "# Print out\n",
    "print(\"Mean height (with weights):\", height_mean_weighted)\n",
    "print(\"Standard error (with weights):\", height_se_weighted)\n",
    "print(\"90% confidence interval (with weights):\", height_ci_weighted)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean height (with weights): 170.49723088968463\n",
      "Standard error (with weights): 0.03523536974893468\n",
      "90% confidence interval (with weights): [170.43896759 170.55598123]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Comparing the results, we can see that correct weighting does affect the estimates. \n",
    "The mean height with weights is higher than the mean height without weights, and the standard error is larger as well. \n",
    "Additionally, the confidence interval with weights is wider than the confidence interval without weights. \n",
    "This indicates that correct weighting is important for obtaining accurate estimates from the BRFSS data."
   ],
   "id": "97e63cde75874431"
  },
  {
   "cell_type": "code",
   "id": "411c4426",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T20:23:14.151363Z",
     "start_time": "2025-01-10T20:23:14.145360Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
