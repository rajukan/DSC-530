{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfa5c464",
   "metadata": {},
   "source": [
    "### Exercise 12.1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42fcb1e",
   "metadata": {},
   "source": [
    "The linear model I used in this chapter has the obvious drawback that it is linear, and there is no reason to expect prices to change linearly over time. We can add flexibility to the model by adding a quadratic term. Use a quadratic model to fit the time series of daily prices, and use the model to generate predictions. "
   ]
  },
  {
   "cell_type": "code",
   "id": "570c612d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T03:01:27.847629Z",
     "start_time": "2024-11-29T03:01:25.557435Z"
    }
   },
   "source": [
    "# import package and data frame as well as predefined functions\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "\n",
    "import thinkstats2\n",
    "import thinkplot\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "transactions = pd.read_csv(\"mj-clean.csv\", parse_dates=[5])\n",
    "transactions.head()\n",
    "\n",
    "def GroupByDay(transactions, func=np.mean):\n",
    "    \"\"\"Groups transactions by day and compute the daily mean ppg.\n",
    "\n",
    "    transactions: DataFrame of transactions\n",
    "\n",
    "    returns: DataFrame of daily prices\n",
    "    \"\"\"\n",
    "    grouped = transactions[[\"date\", \"ppg\"]].groupby(\"date\")\n",
    "    daily = grouped.aggregate(func)\n",
    "\n",
    "    daily[\"date\"] = daily.index\n",
    "    start = daily.date[0]\n",
    "    one_year = np.timedelta64(1, \"Y\")\n",
    "    daily[\"years\"] = (daily.date - start) / one_year\n",
    "\n",
    "    return daily\n",
    "\n",
    "def GroupByQualityAndDay(transactions):\n",
    "    \"\"\"Divides transactions by quality and computes mean daily price.\n",
    "\n",
    "    transaction: DataFrame of transactions\n",
    "\n",
    "    returns: map from quality to time series of ppg\n",
    "    \"\"\"\n",
    "    groups = transactions.groupby(\"quality\")\n",
    "    dailies = {}\n",
    "    for name, group in groups:\n",
    "        dailies[name] = GroupByDay(group)\n",
    "\n",
    "    return dailies\n",
    "\n",
    "dailies = GroupByQualityAndDay(transactions)\n",
    "\n",
    "def RunLinearModel(daily):\n",
    "    model = smf.ols(\"ppg ~ years\", data=daily)\n",
    "    results = model.fit()\n",
    "    return model, results    \n",
    "\n",
    "def PlotFittedValues(model, results, label=\"\"):\n",
    "    \"\"\"Plots original data and fitted values.\n",
    "    \"\"\"\n",
    "    \n",
    "    years = model.exog[:, 1]\n",
    "    values = model.endog\n",
    "    thinkplot.Scatter(years, values, s=15, label=label)\n",
    "    thinkplot.Plot(years, results.fittedvalues, label=\"model\", color=\"#ff7f00\")\n",
    "    \n",
    "def PlotPredictions(daily, years, iters=101, percent=90, func=RunLinearModel):\n",
    "    # find confidence level\n",
    "    result_seq = SimulateResults(daily, iters=iters, func=func)\n",
    "    p = (100 - percent) / 2\n",
    "    percents = p, 100 - p\n",
    "\n",
    "    predict_seq = GeneratePredictions(result_seq, years, add_resid=True)\n",
    "    low, high = thinkstats2.PercentileRows(predict_seq, percents)\n",
    "    thinkplot.FillBetween(years, low, high, alpha=0.3, color=\"gray\")\n",
    "\n",
    "    predict_seq = GeneratePredictions(result_seq, years, add_resid=False)\n",
    "    low, high = thinkstats2.PercentileRows(predict_seq, percents)\n",
    "    thinkplot.FillBetween(years, low, high, alpha=0.5, color=\"gray\")     \n",
    "    \n",
    "def SimulateResults(daily, iters=101, func=RunLinearModel):\n",
    "    #get simulated dataset using linear model\n",
    "    _, results = func(daily)\n",
    "    fake = daily.copy()\n",
    "\n",
    "    result_seq = []\n",
    "    for _ in range(iters):\n",
    "        fake.ppg = results.fittedvalues + thinkstats2.Resample(results.resid)\n",
    "        _, fake_results = func(fake)\n",
    "        result_seq.append(fake_results)\n",
    "\n",
    "    return result_seq\n",
    "\n",
    "def GeneratePredictions(result_seq, years, add_resid=False):\n",
    "    \n",
    "    n = len(years)\n",
    "    d = dict(Intercept=np.ones(n), years=years, years2=years**2)\n",
    "    predict_df = pd.DataFrame(d)\n",
    "\n",
    "    predict_seq = []\n",
    "    for fake_results in result_seq:\n",
    "        predict = fake_results.predict(predict_df)\n",
    "        if add_resid:\n",
    "            predict += thinkstats2.Resample(fake_results.resid, n)\n",
    "        predict_seq.append(predict)\n",
    "\n",
    "    return predict_seq"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'mj-clean.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 13\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mthinkplot\u001B[39;00m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mstatsmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mformula\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01msmf\u001B[39;00m\n\u001B[1;32m---> 13\u001B[0m transactions \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmj-clean.csv\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparse_dates\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     14\u001B[0m transactions\u001B[38;5;241m.\u001B[39mhead()\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mGroupByDay\u001B[39m(transactions, func\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mmean):\n",
      "File \u001B[1;32m~\\gyan-python-workspace\\jup-workspace\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[0;32m   1013\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m   1014\u001B[0m     dialect,\n\u001B[0;32m   1015\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1022\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[0;32m   1023\u001B[0m )\n\u001B[0;32m   1024\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m-> 1026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\gyan-python-workspace\\jup-workspace\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    617\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    619\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[1;32m--> 620\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    622\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[0;32m    623\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[1;32m~\\gyan-python-workspace\\jup-workspace\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m   1617\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m   1619\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1620\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\gyan-python-workspace\\jup-workspace\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1878\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[0;32m   1879\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1880\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1881\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1882\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1883\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1884\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1885\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1886\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1887\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1888\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1889\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1890\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1891\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[1;32m~\\gyan-python-workspace\\jup-workspace\\venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    868\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    869\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[0;32m    870\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[0;32m    871\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[0;32m    872\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[1;32m--> 873\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    874\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    875\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    876\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    877\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    878\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    879\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    880\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    881\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[0;32m    882\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'mj-clean.csv'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "4fa58652",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T03:01:27.849141Z",
     "start_time": "2024-11-29T03:01:27.849141Z"
    }
   },
   "source": [
    "# the original RunLinearModel use variable \"year\" in original form. to use quadratic model, add year squared.\n",
    "\n",
    "def RunQuadraticModel(daily):\n",
    "    \"\"\"Runs a linear model of prices versus years.\n",
    "\n",
    "    daily: DataFrame of daily prices\n",
    "\n",
    "    returns: model, results\n",
    "    \"\"\"\n",
    "    daily[\"years2\"] = daily.years**2\n",
    "    model = smf.ols(\"ppg ~ years + years2\", data=daily)\n",
    "    results = model.fit()\n",
    "    return model, results"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d42c90fc",
   "metadata": {},
   "source": [
    "# pick 'high' quality to build model\n",
    "name = \"high\"\n",
    "daily = dailies[name]\n",
    "\n",
    "model, results = RunQuadraticModel(daily)\n",
    "results.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "88b4ecab",
   "metadata": {},
   "source": [
    "# make plot\n",
    "PlotFittedValues(model, results, label=name)\n",
    "thinkplot.Config(\n",
    "    title=\"Fitted values\", xlabel=\"Years\", xlim=[-0.1, 3.8], ylabel=\"price per gram ($)\"\n",
    ")\n",
    "\n",
    "years = np.linspace(0, 5, 101)\n",
    "thinkplot.Scatter(daily.years, daily.ppg, alpha=0.1, label=name)\n",
    "PlotPredictions(daily, years, func=RunQuadraticModel)\n",
    "thinkplot.Config(\n",
    "    title=\"predictions\",\n",
    "    xlabel=\"Years\",\n",
    "    xlim=[years[0] - 0.1, years[-1] + 0.1],\n",
    "    ylabel=\"Price per gram ($)\",\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a4fff6ac",
   "metadata": {},
   "source": [
    "#### now the model has a change of slope, but it is continuous to cover some missed values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcab2ae",
   "metadata": {},
   "source": [
    "### Exercise 12.2\n",
    "Write a definition for a class named SerialCorrelationTest that extends HypothesisTest from HypothesisTest. It should take a series and a lag as data, compute the serial correlation of the series with the given lag, and then compute the p-value of the observed correlation.\n",
    "\n",
    "Use this class to test whether the serial correlation in raw price data is statistically significant. Also test the residuals of the linear model and (if you did the previous exercise), the quadratic model."
   ]
  },
  {
   "cell_type": "code",
   "id": "5ef35939",
   "metadata": {},
   "source": [
    "# build the class\n",
    "class SerialCorrelationTest(thinkstats2.HypothesisTest):\n",
    "    \"\"\"Tests serial correlations by permutation.\"\"\"\n",
    "\n",
    "    def TestStatistic(self, data):\n",
    "        \"\"\"Computes the test statistic.\n",
    "\n",
    "        data: tuple of xs and ys\n",
    "        \"\"\"\n",
    "        series, lag = data\n",
    "        test_stat = abs(SerialCorr(series, lag))\n",
    "        return test_stat\n",
    "\n",
    "    def RunModel(self):\n",
    "        \"\"\"Run the model of the null hypothesis.\n",
    "\n",
    "        returns: simulated data\n",
    "        \"\"\"\n",
    "        series, lag = self.data\n",
    "        permutation = series.reindex(np.random.permutation(series.index))\n",
    "        return permutation, lag"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "27cff47b",
   "metadata": {},
   "source": [
    "# test the correlation between consecutive prices\n",
    "\n",
    "def SerialCorr(series, lag=1):\n",
    "    xs = series[lag:]\n",
    "    ys = series.shift(lag)[lag:]\n",
    "    corr = thinkstats2.Corr(xs, ys)\n",
    "    return corr\n",
    "name = \"high\"\n",
    "daily = dailies[name]\n",
    "\n",
    "series = daily.ppg\n",
    "test = SerialCorrelationTest((series, 1))\n",
    "pvalue = test.PValue()\n",
    "print(test.actual, pvalue)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b098af5a",
   "metadata": {},
   "source": [
    "#### Correlation is strong and statistics significant since the p-value is small."
   ]
  },
  {
   "cell_type": "code",
   "id": "5638483f",
   "metadata": {},
   "source": [
    "# test for serial correlation in residuals of the linear model\n",
    "\n",
    "_, results = RunLinearModel(daily)\n",
    "series = results.resid\n",
    "test = SerialCorrelationTest((series, 1))\n",
    "pvalue = test.PValue()\n",
    "print(test.actual, pvalue)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "73f2311b",
   "metadata": {},
   "source": [
    "#### residual serial correlation is small but statistical sinificant"
   ]
  },
  {
   "cell_type": "code",
   "id": "f0a67e04",
   "metadata": {},
   "source": [
    "# test for serial correlation in residuals of the quadratic model\n",
    "\n",
    "_, results = RunQuadraticModel(daily)\n",
    "series = results.resid\n",
    "test = SerialCorrelationTest((series, 1))\n",
    "pvalue = test.PValue()\n",
    "print(test.actual, pvalue)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ff833f2e",
   "metadata": {},
   "source": [
    "#### in quadratic model, residual serial correlationn is small and NOT statistical sinificant"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
